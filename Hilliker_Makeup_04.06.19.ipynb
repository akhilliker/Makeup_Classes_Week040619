{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missed class materials \n",
    "\n",
    "I missed class on 04/06/19 and 04/08/19 as I was travelling for a conference for work. To make up for the missed classes, I've watched the Panapto videos, completed class exercises, and included a summary of things covered in class, as shown below. It took me a while to catch up, as we were working on a group project when I returned, so I was focused on that for awhile. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class on 04/06/19:\n",
    "\n",
    "Class started with a Review of Bootstrap concepts and 15 minutes to work on copying the column set up of a favortie website.  I choose Twitter.  See file clone_twitter.html.  A screen shot of my website set up is shown below:\n",
    "\n",
    "![alt text](clone_twitter.png)\n",
    "\n",
    "Compared to real Twitter:\n",
    "![alt text](real_twitter.png)\n",
    "\n",
    "I didn't get to the point of adding color or adjusting fonts within the 15 minutes, but I assume I'll get practice with formatting on the homework.  I met the main objective of setting up similar column widths in the grid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we learned how to deploy webpages from github. I built a basic page with several links and a picture, which can be found at <a href=\"https://akhilliker.github.io\"></a>. The html code can be found in file index.html. \n",
    "\n",
    "Next, we covered Web scraping using the Beautiful Soup library in python. There are built in functions to parse the webpage contents into objects.  These objects can then be extracted by referencing the html tag near the text. Doing this, one can build lists that one can print in their entirety, or call specific parts of the list using indexing.  Presumably this data could be moved in dataframes in pandas, etc. We practiced web scrapping on a 1996 CNN website. My code can be found in Stu_CNN-Unsolved.ipynb and here is a screen shot:\n",
    "![alt text](Stu_CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then learned how to do webscraping within the Pandas library.  Activity Stu_Doctor_Decoder.ipynb contains my attempt at this activity and a screen shot is shown below:\n",
    "![alt text](Stu_Doctor_Decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class on 04/08/18:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tried Splinter, a python library that helps with interactions with a website.  It allows one to automate interactions with the website, such as visiting certain urls, filling in fields, clicking buttons, etc. We can simulate these user interactions via Splinter. Splinter also creates a local copy of the website to practice these interactions. \n",
    "\n",
    "We practiced scraping information from a webpage using Splinter in the activity Stu_splinter.  The file is included and called Stu_Splinter.ipynb.  A screen shot is shown below. \n",
    "![alt text](Stu_Splinter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I installed and created directories for MongoDB.  I then completed the \"discussion activity\" on my own to learn about Mongo DB from the .ppt and from reading articles online (summary here): MongoDB is a \"noSQL\" database, meaning that the data isn't  structured in tables, like SQL.  This is handy for data from scraping websites or things like medical records, where the entries vary a lot from record to record.  The data is stored in BSON format, which is a type of compressed JSON. A Mongo database is made up of multiple collections and each collection is made of multiple documents. A collection is equivalent to a table in SQL, but won't necessarily have a structure like a table. Each \"document\" looks like what I would consider a record or row in SQL.  But these documents don't have to have the same types of fields (where in a SQL data base, each record would have the same catagories and empty catagories would be null). Columns in SQL are equivalent to a field in NoSQL, but not every document in a collection will have the same fields.\n",
    "\n",
    "Advantages to MongoDB (according to Mongo)? Open source and therefore low cost. Doesn't need to be relational, so can handle large volumes of data that isn't very structured. \n",
    "Advantages to MongoDB (according to other sources)? Can store lots of different data types. It is apparently 100x faster than a relational database as individual documents can be retrieved by indexing. You can disctribute data to several machines, allowing faster processing of big datasets. \n",
    "Disadvantages to MongoDB? Doesn't support joins (some sites say the lack of complex joins is an advantage), but these can be hand coded. As it stores key names for every value, it often contains redundent data and requires more memory. You can only next up to 100 levels. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then stepped through using MongoDB in the terminal, according to the instructions in the Instruction notebook (RICH201901DATA3 > 12-Web-Scraping-and-Document-Databases >1 > Activities >  01-Ins_MongoBasics\n",
    " to 04-Stu_DumpsterDB). I save a text file from my work in the terminal; the file is called MongoDBactivities.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I played around with MongoDB Compass to make a new database about the students in my research lab.  A screen capture is shown:\n",
    "![alt text](MongoDB_Compass.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we used MongoDB in python by importing the PyMongo library.  I built a database and added new entries based on user input.  See \"MongoGrove\" file for the code. A screen capture is shown below:\n",
    "![alt text](MongoGrove.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
